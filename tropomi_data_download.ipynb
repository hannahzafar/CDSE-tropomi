{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60be7f84-0d30-40b3-ba1f-78058c80cf45",
   "metadata": {},
   "source": [
    "# Jupyter Notebook used for exploring and drafting script to automate downloads of Sentinel-5P CO and CH4 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7221d3-961f-4638-919a-95268e47e069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime, time\n",
    "import pandas as pd\n",
    "import sys \n",
    "import os\n",
    "import zipfile\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6985a63d-dde1-4c46-bf4b-f82e15d87c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copernicus credentials function\n",
    "def get_credentials():\n",
    "    print('Enter your Copernicus Data Space Ecosystem credentials')\n",
    "    user = input('username: ')\n",
    "    passwd = input('password: ')\n",
    "    return user, passwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16ae1f2-f269-4a3e-9f21-d4065b583693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define authentication variables\n",
    "client_id = 'cdse-public'\n",
    "token_url = 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token'\n",
    "grant_type = 'password'\n",
    "\n",
    "while True:\n",
    "    username, password = get_credentials()\n",
    "\n",
    "\n",
    "    # Make a POST request to obtain an authentication token\n",
    "    auth_data = {'client_id': client_id, 'username': username, 'password': password, \n",
    "               'grant_type': grant_type}\n",
    "    response = requests.post(token_url, data=auth_data)\n",
    "    \n",
    "    # Confirm request successful\n",
    "    if response.status_code == 200:\n",
    "         # Parse the JSON response and extract token\n",
    "         token_data = response.json()\n",
    "         access_token = token_data.get('access_token')\n",
    "         # Check access token retrieved + print if so\n",
    "         if access_token:\n",
    "             print(f'Authentication Token Retrieved')\n",
    "             break\n",
    "         else:\n",
    "             print('Token not found in the response')\n",
    "    else:\n",
    "        text_dict = json.loads(response.text)\n",
    "        print(f'Failed to obtain Authentication Token. Error: {text_dict['error_description']}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49378daa-d5d6-4f9b-8c17-13c534de054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select parameter function\n",
    "def select_parameter(choice):\n",
    "    # print('Sentinel-5P parameter: \\n1. CO \\n2. CH4')\n",
    "    # choice = int(input('Select:'))\n",
    "    if choice == 1:\n",
    "        parameter = 'CH4'\n",
    "        product = 'L2__CH4___' # SENTINEL-5P CH4 nomenclature\n",
    "    elif choice == 2:\n",
    "        parameter = 'CO'\n",
    "        product = 'L2__CO____' # SENTINEL-5P CO\n",
    "    else: \n",
    "        print('Invalid selection') \n",
    "        select_parameter()\n",
    "    return parameter, product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63792207-6107-464e-bc9b-99e5d3f4d2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function\n",
    "choice = int(input('Select Sentinel-5P parameter: \\n1. CH4\\n2. CO\\n'))\n",
    "parameter, product = select_parameter(choice)\n",
    "# product = 'L2__CH4___'  #override\n",
    "# product = 'L2__CO____' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e1dc31-7957-4f88-bdd6-eeb966eea508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select date of interest\n",
    "while True:\n",
    "    date_str = input('Enter date of interest (YYYYMMDD): ')\n",
    "    try:\n",
    "        date = datetime.strptime(date_str, '%Y%m%d')\n",
    "        break\n",
    "    except ValueError:\n",
    "        print(f\"Invalid date string: {date_str}. Try again\")\n",
    "\n",
    "# date_str = '09012024' #overwrite date for testing purposes\n",
    "date = datetime.strptime(date_str, '%Y%m%d')\n",
    "start_date = date.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] +'Z'\n",
    "end_date = datetime.combine(date,time.max).strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] +'Z'\n",
    "# print(start_date, end_date, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940de132-9806-42e7-9f92-c5e7c4c79547",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OData requires manually building the URL, which is tedious, so I used OpenSearch for querying\n",
    "# Search for Sentinel-5P data using OpenSearch \n",
    "opensearch_url = 'https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel5P/search.json'\n",
    "\n",
    "# Define the query parameters for Sentinel-5P CH4 and CO data\n",
    "query_params = { \n",
    "    'startDate': start_date, \n",
    "    'completionDate': end_date, # Date range for the current day\n",
    "    'productType': product,  \n",
    "}\n",
    "# Make a GET request to the OpenSearch Catalog\n",
    "response = requests.get(opensearch_url, \n",
    "                            params=query_params).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0009a5-a620-4319-b877-fbba109ac61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View features in response\n",
    "response_df = pd.DataFrame.from_dict(response['features'])\n",
    "response_df\n",
    "# response_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39defaf-9e2e-445a-b60f-15febf086968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View values contained in 'properties' header\n",
    "testsub_df = pd.DataFrame.from_dict(response_df['properties'].values.tolist())\n",
    "# testsub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e112f2fc-3f72-40c0-ac4c-0f37436481ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The response json file contains details about each item in the query, including an 'id' and a download url. \n",
    "# I could not get the OpenSearch download url to work with my authentication token, so I moved on to using the download\n",
    "# feature with OData using the id\n",
    "\n",
    "# Extract download URLs and filenames\n",
    "download_urls = response_df['properties'].apply(lambda x: x.get('services').get('download').get('url')).values.tolist()\n",
    "titles = response_df['properties'].apply(lambda x: x.get('title')).values.tolist()\n",
    "ids = response_df['id'].values.tolist() #ids needed to download data\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e65f2-3aec-440c-ade7-4f21fb610985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download files\n",
    "# create a list of urls from ids\n",
    "urls = []\n",
    "for id in ids:\n",
    "    urls.append('https://download.dataspace.copernicus.eu/odata/v1/Products(' + id + ')/$value')\n",
    "\n",
    "# urls = urls[:3] #testing just 3 urls\n",
    "# print(urls)\n",
    "\n",
    "# Create a session and update headers\n",
    "headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "session = requests.Session()\n",
    "session.headers.update(headers)\n",
    "\n",
    "download_directory = 'tropomi_download_' +  product + '_' + date_str\n",
    "check_set = set()\n",
    "\n",
    "for url, title in zip(urls, titles): # Loop over the download urls and titles of files performing GET request\n",
    "    filename = title[:-3] + '.zip'\n",
    "    response = session.get(url, stream=True)\n",
    "    check_set.add(response.status_code)\n",
    "    # print(filename)\n",
    "    # print(response.text)\n",
    "    \n",
    "    if response.status_code == 200: # Check if the request was successful\n",
    "        zip_buffer = io.BytesIO(response.content) \n",
    "        with zipfile.ZipFile(zip_buffer, 'r') as zip_file:\n",
    "            zip_file.extractall(download_directory)\n",
    "            print(f\"Extracting {filename} to {download_directory}\")\n",
    "        \n",
    "    else: \n",
    "        print(f\"Failed to download: {filename} from {url} (Status code: {response.status_code})\") \n",
    "        print(response.text)\n",
    "\n",
    "if check_set == {200}:\n",
    "    print('Download complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1274ff3d-e026-4c70-b4f5-d92e0362f3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f1650d-ec89-4b7d-9afc-b1489c28f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Token Refresh #################\n",
    "# refresh_url = 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token'\n",
    "\n",
    "# headers = {'Content-Type' : 'application/x-www-form-urlencoded'}\n",
    "# auth_data = {'refresh_token': token_data.get('refresh_token'),\n",
    "#             'client_id' : client_id,\n",
    "#             'grant_type' : 'refresh_token'}\n",
    "             \n",
    "# response = requests.post(refresh_url, data=auth_data, headers=headers)\n",
    "# token_data = response.json()\n",
    "# access_token =token_data.get('access_token')\n",
    "# token_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c56bb61-314f-4c65-afa5-d5a03545c11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7c526f-3918-449f-b34f-dd88be14a24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Explore query parameters\n",
    "# import xml.etree.ElementTree as ET\n",
    "# url = 'https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel5P/describe.xml'\n",
    "# response = requests.get(url)\n",
    "\n",
    "# # import xml.dom.minidom\n",
    "# # dom = xml.dom.minidom.parseString(response.content)\n",
    "# # pretty_xml = dom.toprettyxml()\n",
    "# # print(pretty_xml)\n",
    "# root = ET.fromstring(response.content)\n",
    "# ET.indent(root)\n",
    "# print(ET.tostring(root, encoding='unicode'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6413b0-49a4-4aeb-b89d-f38d953bc017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Explore query parameters for SENTINEL-5p\n",
    "# json = requests.get(\"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?startDate=2021-07-01T00:00:00Z&completionDate=2021-07-31T23:59:59Z&sortParam=startDate&maxRecords=20\").json()\n",
    "# pd.DataFrame.from_dict(json['features']).head(3)\n",
    "\n",
    "# import pandas as pd\n",
    "# json = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=PublicationDate ge 2019-05-15T00:00:00.000Z and PublicationDate le 2019-05-16T00:00:00.000Z\").json()\n",
    "# df = pd.DataFrame.from_dict(json['value'])\n",
    "# columns_to_print = ['Id', 'Name','S3Path','GeoFootprint']  \n",
    "# df[columns_to_print].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec2cfd0-9fab-437a-a2b1-3143c65c4d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Explore query parameters for SENTINEL-5p\n",
    "# import xml.etree.ElementTree as ET\n",
    "# url = 'https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel5P/describe.xml'\n",
    "# response = requests.get(url)\n",
    "# print('Query-able Parameters')\n",
    "# root = ET.fromstring(response.content)\n",
    "# # for child in root:\n",
    "# #     print(child.tag, child.text,)\n",
    "# # for child in root:\n",
    "# #      print(child.tag, child.attrib)\n",
    "# #     # if child.tag.endswith('ShortName') or child.tag.endswith('Description'):\n",
    "# #         print(f\"{child.tag}: {child.text}\")\n",
    "# for child in root:\n",
    "#     print(child.tag, child.text)\n",
    "#     for subchild in child:\n",
    "#         print(f'\\t{subchild.tag} {subchild.attrib}')\n",
    "#         for subchild2 in subchild:\n",
    "#             print(f'\\t\\t{subchild2.tag} {subchild2.attrib}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e936e026-122c-4a46-935b-5dc049099ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4908e8-329e-4a42-9f5f-fb1a84484cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Search for Sentinenel 5P data using OData\n",
    "# odata_url = 'https://catalogue.dataspace.copernicus.eu/odata/v1/Products'\n",
    "# query_params_CH4 = {\n",
    "#     '$filter': '(Collection/Name eq â€˜SENTINEL-5P)',\n",
    "#     'startDate': start_date, \n",
    "#     'completionDate': end_date, # Date range for the current day\n",
    "#     'productType': 'L2__CH4___',  # SENTINEL-5P CH4\n",
    "# }\n",
    "# response_CH4 = requests.get(odata_url, params=query_params_CH4)\n",
    "# response_CH4.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17184cb-76b7-4b6f-8521-c4d48a8d35fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1eb0b0-852a-4669-a383-570a2a6dc541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing download URL from OpenSearch\n",
    "# Create a session and update headers\n",
    "# headers = {\"Authorization\": f\"Bearer {access_token}\", 'Content-Type': 'application/octet-stream'}\n",
    "# headers = {\"Authorization\": access_token}\n",
    "# session = requests.Session()\n",
    "# session.headers.update(headers)\n",
    "\n",
    "\n",
    "# # Perform the GET request for downloads\n",
    "# for url, title in zip(download_urls, filenames):\n",
    "#     save_path = title[:-3]\n",
    "#     response = session.get(url, stream=True)\n",
    "    \n",
    "#     if response.status_code == 200: # Check if the request was successful\n",
    "#         print('Success')\n",
    "#         # with open(save_path, \"wb\") as file: # save to specified path\n",
    "#         #     # for chunk in response.iter_content(chunk_size=8192):\n",
    "#         #     #     if chunk:  # filter out keep-alive new chunks\n",
    "#         #     #         file.write(chunk)\n",
    "#         #     # print(f\"Downloaded: {save_path}\") \n",
    "#     else: \n",
    "#         print(f\"Failed to download: {save_path} from {url} (Status code: {response.status_code})\") \n",
    "#         print(response.text)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30b05d3-bacc-45ae-8392-132ae56d4adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# DUMP #################\n",
    "# prop_df = pd.json_normalize(response_df['properties'])\n",
    "# download_urls = prop_df['services.download.url'].values.tolist()\n",
    "# titles = prop_df['title'].values.tolist()\n",
    "# download_urls\n",
    "# # test_df = pd.json_normalize(response_df['properties'])\n",
    "# # test_df.head()\n",
    "# test2 = pd.DataFrame.from_dict(test['properties'].values.tolist())\n",
    "# test2.head()\n",
    "\n",
    "# features = response_CH4['features']\n",
    "# response_CH4\n",
    "# response_df = pd.DataFrame.from_dict(response_CH4['features']).head()\n",
    "# response_df\n",
    "# # print(CH4_df['properties'][0])\n",
    "# download_url = response_CH4.get('features')\n",
    "# download_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a014220-85e6-43cf-ac4b-ac2e5fdb6819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip_buffer = io.BytesIO() # Create an in-memory ZIP\n",
    "\n",
    "# with zipfile.ZipFile(zip_buffer, 'w',zipfile.ZIP_DEFLATED) as zip_file: # Open ZIP for writing\n",
    "\n",
    "#     for url, title in zip(urls, titles): # Loop over the download urls and titles of files performing GET request\n",
    "#         filename = title[:-3] + '.zip'\n",
    "#         response = session.get(url, stream=True)\n",
    "        \n",
    "#         if response.status_code == 200: # Check if the request was successful\n",
    "#             content_buffer = io.BytesIO() # create in-memory buffer to store download\n",
    "#             for chunk in response.iter_content(chunk_size=8192):\n",
    "#                 if chunk:  # filter out keep-alive new chunks\n",
    "#                     content_buffer.write(chunk) # write response to buffer\n",
    "\n",
    "#             zip_file.writestr(filename, content_buffer.getvalue())\n",
    "#             print(f\"Downloading {filename}\")\n",
    "            \n",
    "#         else: \n",
    "#             print(f\"Failed to download: {filename} from {url} (Status code: {response.status_code})\") \n",
    "#             print(response.text)\n",
    "\n",
    "# # Write ZIP to disk\n",
    "# with open('download.zip', 'wb') as f:\n",
    "#     f.write(zip_buffer.getvalue())\n",
    "\n",
    "# print('Downloads saved to download.zip')\n",
    "            \n",
    "# OLD: this extracts and saves each file separately\n",
    "# for url, title in zip(urls, titles):\n",
    "#     save_path = title[:-3] + '.zip'\n",
    "#     response = session.get(url, stream=True)\n",
    "    \n",
    "#     if response.status_code == 200: # Check if the request was successful\n",
    "#         with open(save_path, \"wb\") as file: # save to specified path\n",
    "#             for chunk in response.iter_content(chunk_size=8192):\n",
    "#                 if chunk:  # filter out keep-alive new chunks\n",
    "#                     file.write(chunk)\n",
    "#             print(f\"Downloaded: {title}\")\n",
    "            \n",
    "#     else: \n",
    "#         print(f\"Failed to download: {save_path} from {url} (Status code: {response.status_code})\") \n",
    "#         print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis]",
   "language": "python",
   "name": "conda-env-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
